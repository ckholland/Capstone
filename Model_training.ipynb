{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "aa5e349a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded: pendulum_data.csv\n",
      "Shape: (99499, 26)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>company</th>\n",
       "      <th>document_id</th>\n",
       "      <th>post_id</th>\n",
       "      <th>post_title</th>\n",
       "      <th>post_url</th>\n",
       "      <th>media_url</th>\n",
       "      <th>upload_date</th>\n",
       "      <th>impression_count</th>\n",
       "      <th>pred_impressions</th>\n",
       "      <th>impression_count_comb</th>\n",
       "      <th>...</th>\n",
       "      <th>comment_count</th>\n",
       "      <th>share_count</th>\n",
       "      <th>communities</th>\n",
       "      <th>snippet_lang</th>\n",
       "      <th>snippet_text</th>\n",
       "      <th>snippet_source</th>\n",
       "      <th>duration</th>\n",
       "      <th>offset</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>sentiment_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Housing Market (Buying/Selling Homes)</td>\n",
       "      <td>bcdda782-5984-36d7-b747-adbe88b56022</td>\n",
       "      <td>5a16d0c50fb23295adb072c861be5e33</td>\n",
       "      <td>NaN</td>\n",
       "      <td>https://www.tiktok.com/@thisistechtoday/video/...</td>\n",
       "      <td>https://www.tiktok.com/@thisistechtoday/video/...</td>\n",
       "      <td>2025-04-03T20:49:25</td>\n",
       "      <td>21800000</td>\n",
       "      <td>1.785211e+04</td>\n",
       "      <td>21800000.0</td>\n",
       "      <td>...</td>\n",
       "      <td>82.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>en</td>\n",
       "      <td>type, I decided to make some videos at the pla...</td>\n",
       "      <td>description</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Positive</td>\n",
       "      <td>0.941140</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Housing Market (Buying/Selling Homes)</td>\n",
       "      <td>ef28b6bf-33d3-3e34-9ca8-5d1bb495b020</td>\n",
       "      <td>f727cbb3f43e389a93a025a2aa1337a3</td>\n",
       "      <td>Zillow | Are We Doing This?</td>\n",
       "      <td>https://www.youtube.com/watch?v=mAxS5WZqcho&amp;t=0s</td>\n",
       "      <td>https://www.youtube.com/watch?v=mAxS5WZqcho</td>\n",
       "      <td>2025-02-28T23:01:34</td>\n",
       "      <td>18626940</td>\n",
       "      <td>1.559422e+04</td>\n",
       "      <td>18626940.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>en</td>\n",
       "      <td>( music playing ) I'm thinking of &lt;strong&gt;buyi...</td>\n",
       "      <td>transcript</td>\n",
       "      <td>14.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>0.587764</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Housing Market (Buying/Selling Homes)</td>\n",
       "      <td>407ddf77-0117-361b-a255-881b1bb45caa</td>\n",
       "      <td>a012e9ad16713e2ebe48361fb4c98b3f</td>\n",
       "      <td>NaN</td>\n",
       "      <td>https://www.tiktok.com/@lic.manene/video/75459...</td>\n",
       "      <td>https://www.tiktok.com/@lic.manene/video/75459...</td>\n",
       "      <td>2025-09-03T20:01:25</td>\n",
       "      <td>13900000</td>\n",
       "      <td>4.545480e+04</td>\n",
       "      <td>13900000.0</td>\n",
       "      <td>...</td>\n",
       "      <td>9041.0</td>\n",
       "      <td>736100.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>en</td>\n",
       "      <td>legal advice on the consequences of &lt;strong&gt;se...</td>\n",
       "      <td>image_caption</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>0.637891</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Housing Market (Buying/Selling Homes)</td>\n",
       "      <td>86e453de-cc84-3fc4-9077-232f8e8b7110</td>\n",
       "      <td>ff2247ead37e351cae0c9987802ae8d3</td>\n",
       "      <td>We’re Moving to Hawaii *emotional*</td>\n",
       "      <td>https://www.youtube.com/watch?v=49OSWOITnNA&amp;t=...</td>\n",
       "      <td>https://www.youtube.com/watch?v=49OSWOITnNA</td>\n",
       "      <td>2025-08-31T16:58:39</td>\n",
       "      <td>10080500</td>\n",
       "      <td>4.488331e+06</td>\n",
       "      <td>10080500.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[77, 77]</td>\n",
       "      <td>en</td>\n",
       "      <td>special gift. All right. Special gift. You're ...</td>\n",
       "      <td>transcript</td>\n",
       "      <td>16.0</td>\n",
       "      <td>242.0</td>\n",
       "      <td>Positive</td>\n",
       "      <td>0.544222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Housing Market (Buying/Selling Homes)</td>\n",
       "      <td>1d3ff552-d324-391a-9537-7d5b9b8cd16b</td>\n",
       "      <td>f23749a3b03a376591a200b7e4c00c22</td>\n",
       "      <td>NaN</td>\n",
       "      <td>https://twitter.com/jacksonhinklle/status/1884...</td>\n",
       "      <td>https://twitter.com/jacksonhinklle/status/1884...</td>\n",
       "      <td>2025-01-29T19:33:05</td>\n",
       "      <td>8062540</td>\n",
       "      <td>5.134603e+05</td>\n",
       "      <td>513460.0</td>\n",
       "      <td>...</td>\n",
       "      <td>4968.0</td>\n",
       "      <td>13798.0</td>\n",
       "      <td>[]</td>\n",
       "      <td>en</td>\n",
       "      <td>in infrastructure, high speed rail, healthcare...</td>\n",
       "      <td>description</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>0.773371</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 26 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 company  \\\n",
       "0  Housing Market (Buying/Selling Homes)   \n",
       "1  Housing Market (Buying/Selling Homes)   \n",
       "2  Housing Market (Buying/Selling Homes)   \n",
       "3  Housing Market (Buying/Selling Homes)   \n",
       "4  Housing Market (Buying/Selling Homes)   \n",
       "\n",
       "                            document_id                           post_id  \\\n",
       "0  bcdda782-5984-36d7-b747-adbe88b56022  5a16d0c50fb23295adb072c861be5e33   \n",
       "1  ef28b6bf-33d3-3e34-9ca8-5d1bb495b020  f727cbb3f43e389a93a025a2aa1337a3   \n",
       "2  407ddf77-0117-361b-a255-881b1bb45caa  a012e9ad16713e2ebe48361fb4c98b3f   \n",
       "3  86e453de-cc84-3fc4-9077-232f8e8b7110  ff2247ead37e351cae0c9987802ae8d3   \n",
       "4  1d3ff552-d324-391a-9537-7d5b9b8cd16b  f23749a3b03a376591a200b7e4c00c22   \n",
       "\n",
       "                           post_title  \\\n",
       "0                                 NaN   \n",
       "1         Zillow | Are We Doing This?   \n",
       "2                                 NaN   \n",
       "3  We’re Moving to Hawaii *emotional*   \n",
       "4                                 NaN   \n",
       "\n",
       "                                            post_url  \\\n",
       "0  https://www.tiktok.com/@thisistechtoday/video/...   \n",
       "1   https://www.youtube.com/watch?v=mAxS5WZqcho&t=0s   \n",
       "2  https://www.tiktok.com/@lic.manene/video/75459...   \n",
       "3  https://www.youtube.com/watch?v=49OSWOITnNA&t=...   \n",
       "4  https://twitter.com/jacksonhinklle/status/1884...   \n",
       "\n",
       "                                           media_url          upload_date  \\\n",
       "0  https://www.tiktok.com/@thisistechtoday/video/...  2025-04-03T20:49:25   \n",
       "1        https://www.youtube.com/watch?v=mAxS5WZqcho  2025-02-28T23:01:34   \n",
       "2  https://www.tiktok.com/@lic.manene/video/75459...  2025-09-03T20:01:25   \n",
       "3        https://www.youtube.com/watch?v=49OSWOITnNA  2025-08-31T16:58:39   \n",
       "4  https://twitter.com/jacksonhinklle/status/1884...  2025-01-29T19:33:05   \n",
       "\n",
       "   impression_count  pred_impressions  impression_count_comb  ...  \\\n",
       "0          21800000      1.785211e+04             21800000.0  ...   \n",
       "1          18626940      1.559422e+04             18626940.0  ...   \n",
       "2          13900000      4.545480e+04             13900000.0  ...   \n",
       "3          10080500      4.488331e+06             10080500.0  ...   \n",
       "4           8062540      5.134603e+05               513460.0  ...   \n",
       "\n",
       "  comment_count share_count  communities snippet_lang  \\\n",
       "0          82.0        20.0          NaN           en   \n",
       "1           NaN         NaN          NaN           en   \n",
       "2        9041.0    736100.0          NaN           en   \n",
       "3           NaN         NaN     [77, 77]           en   \n",
       "4        4968.0     13798.0           []           en   \n",
       "\n",
       "                                        snippet_text  snippet_source  \\\n",
       "0  type, I decided to make some videos at the pla...     description   \n",
       "1  ( music playing ) I'm thinking of <strong>buyi...      transcript   \n",
       "2  legal advice on the consequences of <strong>se...   image_caption   \n",
       "3  special gift. All right. Special gift. You're ...      transcript   \n",
       "4  in infrastructure, high speed rail, healthcare...     description   \n",
       "\n",
       "   duration  offset sentiment sentiment_score  \n",
       "0       NaN     NaN  Positive        0.941140  \n",
       "1      14.0     0.0   Neutral        0.587764  \n",
       "2       NaN     NaN   Neutral        0.637891  \n",
       "3      16.0   242.0  Positive        0.544222  \n",
       "4       NaN     NaN   Neutral        0.773371  \n",
       "\n",
       "[5 rows x 26 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load in the data\n",
    "import pandas as pd\n",
    "\n",
    "file = \"pendulum_data.csv\"\n",
    "\n",
    "df = pd.read_csv(file)\n",
    "print(\"Loaded:\", file)\n",
    "print(\"Shape:\", df.shape)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5d6f5a6c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Kept columns: ['topic', 'upload_date', 'impression_count_comb', 'platform', 'snippet_text']\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>topic</th>\n",
       "      <th>upload_date</th>\n",
       "      <th>impression_count_comb</th>\n",
       "      <th>platform</th>\n",
       "      <th>snippet_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Housing Market (Buying/Selling Homes)</td>\n",
       "      <td>2025-04-03T20:49:25</td>\n",
       "      <td>21800000.0</td>\n",
       "      <td>TikTok</td>\n",
       "      <td>type, I decided to make some videos at the pla...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Housing Market (Buying/Selling Homes)</td>\n",
       "      <td>2025-02-28T23:01:34</td>\n",
       "      <td>18626940.0</td>\n",
       "      <td>YouTube</td>\n",
       "      <td>( music playing ) I'm thinking of &lt;strong&gt;buyi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Housing Market (Buying/Selling Homes)</td>\n",
       "      <td>2025-09-03T20:01:25</td>\n",
       "      <td>13900000.0</td>\n",
       "      <td>TikTok</td>\n",
       "      <td>legal advice on the consequences of &lt;strong&gt;se...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Housing Market (Buying/Selling Homes)</td>\n",
       "      <td>2025-08-31T16:58:39</td>\n",
       "      <td>10080500.0</td>\n",
       "      <td>YouTube</td>\n",
       "      <td>special gift. All right. Special gift. You're ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Housing Market (Buying/Selling Homes)</td>\n",
       "      <td>2025-01-29T19:33:05</td>\n",
       "      <td>513460.0</td>\n",
       "      <td>Twitter</td>\n",
       "      <td>in infrastructure, high speed rail, healthcare...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                   topic          upload_date  \\\n",
       "0  Housing Market (Buying/Selling Homes)  2025-04-03T20:49:25   \n",
       "1  Housing Market (Buying/Selling Homes)  2025-02-28T23:01:34   \n",
       "2  Housing Market (Buying/Selling Homes)  2025-09-03T20:01:25   \n",
       "3  Housing Market (Buying/Selling Homes)  2025-08-31T16:58:39   \n",
       "4  Housing Market (Buying/Selling Homes)  2025-01-29T19:33:05   \n",
       "\n",
       "   impression_count_comb platform  \\\n",
       "0             21800000.0   TikTok   \n",
       "1             18626940.0  YouTube   \n",
       "2             13900000.0   TikTok   \n",
       "3             10080500.0  YouTube   \n",
       "4               513460.0  Twitter   \n",
       "\n",
       "                                        snippet_text  \n",
       "0  type, I decided to make some videos at the pla...  \n",
       "1  ( music playing ) I'm thinking of <strong>buyi...  \n",
       "2  legal advice on the consequences of <strong>se...  \n",
       "3  special gift. All right. Special gift. You're ...  \n",
       "4  in infrastructure, high speed rail, healthcare...  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Keep only the necessary columns\n",
    "desired_cols = ['company', 'upload_date', 'impression_count_comb', 'platform', 'snippet_text']\n",
    "\n",
    "present = [c for c in desired_cols if c in df.columns]\n",
    "\n",
    "df = df[present].copy()\n",
    "\n",
    "# Rename company to topic\n",
    "df.rename(columns={\"company\": \"topic\"}, inplace=True)\n",
    "\n",
    "print(\"Kept columns:\", df.columns.tolist())\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8b12694a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded: interview_schedule_2025.csv\n",
      "Shape: (132, 4)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Month</th>\n",
       "      <th>Year</th>\n",
       "      <th>Start Date</th>\n",
       "      <th>End Date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>2015</td>\n",
       "      <td>2-Jan-15</td>\n",
       "      <td>26-Jan-15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>2015</td>\n",
       "      <td>29-Jan-15</td>\n",
       "      <td>23-Feb-15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>2015</td>\n",
       "      <td>26-Feb-15</td>\n",
       "      <td>23-Mar-15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>2015</td>\n",
       "      <td>26-Mar-15</td>\n",
       "      <td>25-Apr-15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>2015</td>\n",
       "      <td>29-Apr-15</td>\n",
       "      <td>23-May-15</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Month  Year Start Date   End Date\n",
       "0      1  2015   2-Jan-15  26-Jan-15\n",
       "1      2  2015  29-Jan-15  23-Feb-15\n",
       "2      3  2015  26-Feb-15  23-Mar-15\n",
       "3      4  2015  26-Mar-15  25-Apr-15\n",
       "4      5  2015  29-Apr-15  23-May-15"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load score dates\n",
    "schedule_file = \"interview_schedule_2025.csv\"\n",
    "schedule_df = pd.read_csv(schedule_file)\n",
    "print(\"Loaded:\", schedule_file)\n",
    "print(\"Shape:\", schedule_df.shape)\n",
    "schedule_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "44ec3081",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Assigned months: [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>topic</th>\n",
       "      <th>upload_date</th>\n",
       "      <th>impression_count_comb</th>\n",
       "      <th>platform</th>\n",
       "      <th>snippet_text</th>\n",
       "      <th>Month</th>\n",
       "      <th>Year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Housing Market (Buying/Selling Homes)</td>\n",
       "      <td>2025-04-03 20:49:25</td>\n",
       "      <td>21800000.0</td>\n",
       "      <td>TikTok</td>\n",
       "      <td>type, I decided to make some videos at the pla...</td>\n",
       "      <td>4</td>\n",
       "      <td>2025</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Housing Market (Buying/Selling Homes)</td>\n",
       "      <td>2025-02-28 23:01:34</td>\n",
       "      <td>18626940.0</td>\n",
       "      <td>YouTube</td>\n",
       "      <td>( music playing ) I'm thinking of &lt;strong&gt;buyi...</td>\n",
       "      <td>3</td>\n",
       "      <td>2025</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Housing Market (Buying/Selling Homes)</td>\n",
       "      <td>2025-09-03 20:01:25</td>\n",
       "      <td>13900000.0</td>\n",
       "      <td>TikTok</td>\n",
       "      <td>legal advice on the consequences of &lt;strong&gt;se...</td>\n",
       "      <td>9</td>\n",
       "      <td>2025</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Housing Market (Buying/Selling Homes)</td>\n",
       "      <td>2025-08-31 16:58:39</td>\n",
       "      <td>10080500.0</td>\n",
       "      <td>YouTube</td>\n",
       "      <td>special gift. All right. Special gift. You're ...</td>\n",
       "      <td>9</td>\n",
       "      <td>2025</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Housing Market (Buying/Selling Homes)</td>\n",
       "      <td>2025-01-29 19:33:05</td>\n",
       "      <td>513460.0</td>\n",
       "      <td>Twitter</td>\n",
       "      <td>in infrastructure, high speed rail, healthcare...</td>\n",
       "      <td>2</td>\n",
       "      <td>2025</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                   topic         upload_date  \\\n",
       "0  Housing Market (Buying/Selling Homes) 2025-04-03 20:49:25   \n",
       "1  Housing Market (Buying/Selling Homes) 2025-02-28 23:01:34   \n",
       "2  Housing Market (Buying/Selling Homes) 2025-09-03 20:01:25   \n",
       "3  Housing Market (Buying/Selling Homes) 2025-08-31 16:58:39   \n",
       "4  Housing Market (Buying/Selling Homes) 2025-01-29 19:33:05   \n",
       "\n",
       "   impression_count_comb platform  \\\n",
       "0             21800000.0   TikTok   \n",
       "1             18626940.0  YouTube   \n",
       "2             13900000.0   TikTok   \n",
       "3             10080500.0  YouTube   \n",
       "4               513460.0  Twitter   \n",
       "\n",
       "                                        snippet_text  Month  Year  \n",
       "0  type, I decided to make some videos at the pla...      4  2025  \n",
       "1  ( music playing ) I'm thinking of <strong>buyi...      3  2025  \n",
       "2  legal advice on the consequences of <strong>se...      9  2025  \n",
       "3  special gift. All right. Special gift. You're ...      9  2025  \n",
       "4  in infrastructure, high speed rail, healthcare...      2  2025  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Convert date columns to datetimes (explicit formats: upload_date ISO, schedule day-month-year like 17-Dec-24)\n",
    "df['upload_date'] = pd.to_datetime(df['upload_date'], format=\"%Y-%m-%dT%H:%M:%S\", errors='coerce')\n",
    "schedule_df['Start Date'] = pd.to_datetime(schedule_df['Start Date'], format=\"%d-%b-%y\", errors='coerce')\n",
    "schedule_df['End Date'] = pd.to_datetime(schedule_df['End Date'], format=\"%d-%b-%y\", errors='coerce')\n",
    "\n",
    "# Prepare Month/Year columns (nullable integers)\n",
    "df['Month'] = pd.NA\n",
    "df['Year'] = pd.NA\n",
    "\n",
    "def _safe_month(val, fallback_dt):\n",
    "    if pd.isna(val):\n",
    "        return (pd.NA if pd.isna(fallback_dt) else int(fallback_dt.month))\n",
    "    try:\n",
    "        return int(val)\n",
    "    except Exception:\n",
    "        # try parsing textual month (e.g. \"Dec\" / \"December\")\n",
    "        try:\n",
    "            parsed = pd.to_datetime(str(val), errors='coerce')\n",
    "            if pd.notna(parsed):\n",
    "                return int(parsed.month)\n",
    "        except Exception:\n",
    "            pass\n",
    "    return (pd.NA if pd.isna(fallback_dt) else int(fallback_dt.month))\n",
    "\n",
    "def _safe_year(val, fallback_dt):\n",
    "    if pd.isna(val):\n",
    "        return (pd.NA if pd.isna(fallback_dt) else int(fallback_dt.year))\n",
    "    try:\n",
    "        return int(val)\n",
    "    except Exception:\n",
    "        try:\n",
    "            parsed = pd.to_datetime(str(val), errors='coerce')\n",
    "            if pd.notna(parsed):\n",
    "                return int(parsed.year)\n",
    "        except Exception:\n",
    "            pass\n",
    "    return (pd.NA if pd.isna(fallback_dt) else int(fallback_dt.year))\n",
    "\n",
    "# For each schedule interval, assign Month and Year to matching upload_date rows\n",
    "for _, srow in schedule_df[['Start Date', 'End Date', 'Month', 'Year']].dropna(subset=['Start Date', 'End Date']).iterrows():\n",
    "    start, end = srow['Start Date'], srow['End Date']\n",
    "    mon_raw, yr_raw = srow.get('Month'), srow.get('Year')\n",
    "    mon = _safe_month(mon_raw, start)\n",
    "    yr = _safe_year(yr_raw, start)\n",
    "    mask = (df['upload_date'] >= start) & (df['upload_date'] <= end)\n",
    "    df.loc[mask, 'Month'] = mon\n",
    "    df.loc[mask, 'Year'] = yr\n",
    "\n",
    "# convert to nullable integer dtypes for convenience\n",
    "df['Month'] = df['Month'].astype('Int64')\n",
    "df['Year'] = df['Year'].astype('Int64')\n",
    "\n",
    "# Show result\n",
    "print(\"Assigned months:\", sorted(df['Month'].dropna().unique().tolist()))\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d3f3fad3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Removed 18042 rows with upload_date on or before 2024-12-16\n",
      "New shape: (81457, 7)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>topic</th>\n",
       "      <th>upload_date</th>\n",
       "      <th>impression_count_comb</th>\n",
       "      <th>platform</th>\n",
       "      <th>snippet_text</th>\n",
       "      <th>Month</th>\n",
       "      <th>Year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Housing Market (Buying/Selling Homes)</td>\n",
       "      <td>2025-04-03 20:49:25</td>\n",
       "      <td>21800000.0</td>\n",
       "      <td>TikTok</td>\n",
       "      <td>type, I decided to make some videos at the pla...</td>\n",
       "      <td>4</td>\n",
       "      <td>2025</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Housing Market (Buying/Selling Homes)</td>\n",
       "      <td>2025-02-28 23:01:34</td>\n",
       "      <td>18626940.0</td>\n",
       "      <td>YouTube</td>\n",
       "      <td>( music playing ) I'm thinking of &lt;strong&gt;buyi...</td>\n",
       "      <td>3</td>\n",
       "      <td>2025</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Housing Market (Buying/Selling Homes)</td>\n",
       "      <td>2025-09-03 20:01:25</td>\n",
       "      <td>13900000.0</td>\n",
       "      <td>TikTok</td>\n",
       "      <td>legal advice on the consequences of &lt;strong&gt;se...</td>\n",
       "      <td>9</td>\n",
       "      <td>2025</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Housing Market (Buying/Selling Homes)</td>\n",
       "      <td>2025-08-31 16:58:39</td>\n",
       "      <td>10080500.0</td>\n",
       "      <td>YouTube</td>\n",
       "      <td>special gift. All right. Special gift. You're ...</td>\n",
       "      <td>9</td>\n",
       "      <td>2025</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Housing Market (Buying/Selling Homes)</td>\n",
       "      <td>2025-01-29 19:33:05</td>\n",
       "      <td>513460.0</td>\n",
       "      <td>Twitter</td>\n",
       "      <td>in infrastructure, high speed rail, healthcare...</td>\n",
       "      <td>2</td>\n",
       "      <td>2025</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                   topic         upload_date  \\\n",
       "0  Housing Market (Buying/Selling Homes) 2025-04-03 20:49:25   \n",
       "1  Housing Market (Buying/Selling Homes) 2025-02-28 23:01:34   \n",
       "2  Housing Market (Buying/Selling Homes) 2025-09-03 20:01:25   \n",
       "3  Housing Market (Buying/Selling Homes) 2025-08-31 16:58:39   \n",
       "4  Housing Market (Buying/Selling Homes) 2025-01-29 19:33:05   \n",
       "\n",
       "   impression_count_comb platform  \\\n",
       "0             21800000.0   TikTok   \n",
       "1             18626940.0  YouTube   \n",
       "2             13900000.0   TikTok   \n",
       "3             10080500.0  YouTube   \n",
       "4               513460.0  Twitter   \n",
       "\n",
       "                                        snippet_text  Month  Year  \n",
       "0  type, I decided to make some videos at the pla...      4  2025  \n",
       "1  ( music playing ) I'm thinking of <strong>buyi...      3  2025  \n",
       "2  legal advice on the consequences of <strong>se...      9  2025  \n",
       "3  special gift. All right. Special gift. You're ...      9  2025  \n",
       "4  in infrastructure, high speed rail, healthcare...      2  2025  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Remove rows with upload_date on or before 2024-12-16 (preserve rows with missing upload_date)\n",
    "threshold = pd.to_datetime(\"2024-12-16\")\n",
    "\n",
    "mask_remove = df['upload_date'].notna() & (df['upload_date'] <= threshold)\n",
    "removed_count = int(mask_remove.sum())\n",
    "\n",
    "df = df.loc[~mask_remove].copy()\n",
    "\n",
    "print(f\"Removed {removed_count} rows with upload_date on or before {threshold.date()}\")\n",
    "print(\"New shape:\", df.shape)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "71e42747",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                       missing_count  missing_pct\n",
      "Month                           2231         2.74\n",
      "Year                            2231         2.74\n",
      "topic                              0         0.00\n",
      "upload_date                        0         0.00\n",
      "impression_count_comb              0         0.00\n",
      "platform                           0         0.00\n",
      "snippet_text                       0         0.00\n"
     ]
    }
   ],
   "source": [
    "# Count missing values per column (count and percent)\n",
    "missing_counts = df.isna().sum()\n",
    "missing_pct = (df.isna().mean() * 100).round(2)\n",
    "\n",
    "missing_summary = pd.DataFrame({\n",
    "    \"missing_count\": missing_counts,\n",
    "    \"missing_pct\": missing_pct\n",
    "}).sort_values(\"missing_count\", ascending=False)\n",
    "\n",
    "print(missing_summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0da1c374",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Removed 2231 rows with any missing values. New shape: (79226, 7)\n",
      "                       missing_count  missing_pct\n",
      "topic                              0          0.0\n",
      "upload_date                        0          0.0\n",
      "impression_count_comb              0          0.0\n",
      "platform                           0          0.0\n",
      "snippet_text                       0          0.0\n",
      "Month                              0          0.0\n",
      "Year                               0          0.0\n"
     ]
    }
   ],
   "source": [
    "# Drop any rows that contain missing values\n",
    "before_count = len(df)\n",
    "df = df.dropna().copy()\n",
    "removed_count = before_count - len(df)\n",
    "\n",
    "print(f\"Removed {removed_count} rows with any missing values. New shape: {df.shape}\")\n",
    "df.head()\n",
    "\n",
    "missing_counts = df.isna().sum()\n",
    "missing_pct = (df.isna().mean() * 100).round(2)\n",
    "missing_summary = pd.DataFrame({\n",
    "    \"missing_count\": missing_counts,\n",
    "    \"missing_pct\": missing_pct\n",
    "}).sort_values(\"missing_count\", ascending=False)\n",
    "print(missing_summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9655a9b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at cardiffnlp/twitter-roberta-base-sentiment-latest were not used when initializing RobertaForSequenceClassification: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "- This IS expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Device set to use cpu\n",
      "/opt/anaconda3/lib/python3.12/site-packages/transformers/pipelines/text_classification.py:111: UserWarning: `return_all_scores` is now deprecated,  if want a similar functionality use `top_k=None` instead of `return_all_scores=True` or `top_k=1` instead of `return_all_scores=False`.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from transformers import pipeline, AutoTokenizer\n",
    "import torch\n",
    "\n",
    "HF_MODEL_PRIMARY   = \"cardiffnlp/twitter-roberta-base-sentiment-latest\"\n",
    "\n",
    "model_name = HF_MODEL_PRIMARY if 'HF_MODEL_PRIMARY' in globals() else \"cardiffnlp/twitter-roberta-base-sentiment-latest\"\n",
    "text_col = 'snippet_text'\n",
    "if text_col not in df.columns:\n",
    "    raise KeyError(f\"Expected text column '{text_col}' not found in df\")\n",
    "\n",
    "device = 0 if torch.cuda.is_available() else -1\n",
    "\n",
    "# load tokenizer with a safe max length and build pipeline with it\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name, use_fast=True)\n",
    "# enforce a reasonable max length (Roberta-based models typically 512)\n",
    "tokenizer.model_max_length = min(getattr(tokenizer, \"model_max_length\", 512), 512)\n",
    "\n",
    "sent_pipe = pipeline(\n",
    "    \"sentiment-analysis\",\n",
    "    model=model_name,\n",
    "    tokenizer=tokenizer,\n",
    "    device=device,\n",
    "    return_all_scores=True\n",
    ")\n",
    "\n",
    "batch_size = 32\n",
    "scores = []\n",
    "n = len(df)\n",
    "\n",
    "for i in range(0, n, batch_size):\n",
    "    batch_texts = df[text_col].iloc[i:i+batch_size].fillna(\"\").astype(str).tolist()\n",
    "    # ensure inputs are truncated/padded to tokenizer.model_max_length to avoid oversized tensors\n",
    "    results = sent_pipe(batch_texts, truncation=True, padding=True, max_length=tokenizer.model_max_length)\n",
    "    for res in results:\n",
    "        label_scores = {entry['label'].lower(): entry['score'] for entry in res}\n",
    "        pos = label_scores.get('positive', 0.0)\n",
    "        neg = label_scores.get('negative', 0.0)\n",
    "        scores.append(pos - neg)\n",
    "\n",
    "if len(scores) != n:\n",
    "    raise RuntimeError(f\"Score count ({len(scores)}) does not match df length ({n})\")\n",
    "\n",
    "df['sentiment'] = scores\n",
    "print(\"Added 'sentiment' column to df (positive-negative score).\")\n",
    "df.head()\n",
    "#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e1d3162-a506-416e-a4d7-8c6fa72e49a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Compute log(1 + count) and weight sentiment\n",
    "df['sentiment_weighted'] = df['sentiment'] * np.log1p(df['impression_count_comb'])\n",
    "\n",
    "# quick check\n",
    "print(df[['sentiment', 'impression_count_comb', 'sentiment_weighted']].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "955276ff-0a5d-453a-a5c0-74b0db333ea1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aggregate average sentiment_weighted for rows that have Month, Year, and topic\n",
    "agg_df = (\n",
    "    df.dropna(subset=['Month', 'Year', 'topic'])\n",
    "      .groupby(['Year', 'Month', 'topic'], as_index=False)['sentiment_weighted']\n",
    "      .mean()\n",
    "      .rename(columns={'sentiment_weighted': 'sentiment_weighted_avg'})\n",
    ")\n",
    "\n",
    "# optional: sort for readability\n",
    "agg_df = agg_df.sort_values(['Year', 'Month', 'topic']).reset_index(drop=True)\n",
    "\n",
    "print(\"Aggregated shape:\", agg_df.shape)\n",
    "agg_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cb40caa-40cc-40ab-a9dd-d701a7983281",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pivot the aggregated data so each row is a Year-Month and each column is a topic with the weighted score\n",
    "if 'agg_df' not in globals():\n",
    "    raise NameError(\"Expected 'agg_df' to exist from previous cell (aggregated Year, Month, topic).\")\n",
    "\n",
    "wide_df = (\n",
    "    agg_df\n",
    "    .pivot_table(index=['Year', 'Month'], columns='topic', values='sentiment_weighted_avg', aggfunc='first')\n",
    "    .sort_index()\n",
    ")\n",
    "\n",
    "# Convert Year/Month MultiIndex to a PeriodIndex (monthly) for easier time-based handling\n",
    "try:\n",
    "    wide_df.index = pd.PeriodIndex(\n",
    "        year=wide_df.index.get_level_values('Year').astype(int),\n",
    "        month=wide_df.index.get_level_values('Month').astype(int),\n",
    "        freq='M'\n",
    "    )\n",
    "    wide_df.index.name = 'Period'\n",
    "except Exception:\n",
    "    # If conversion fails, keep the Year/Month MultiIndex (ensuring integer dtypes)\n",
    "    wide_df = wide_df.rename_axis(index=['Year', 'Month'])\n",
    "\n",
    "print(\"Wide dataframe shape:\", wide_df.shape)\n",
    "wide_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40eca2d8-3ea4-4617-a502-da5c00eb018b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load MCSI scores\n",
    "scores_file = \"scores.csv\"\n",
    "scores_df = pd.read_csv(scores_file)\n",
    "print(\"Loaded:\", scores_file)\n",
    "print(\"Shape:\", scores_df.shape)\n",
    "scores_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4289113-0c99-4484-bc10-f73536893779",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add MCSI scores to the main data frame\n",
    "wide_df = wide_df.merge(\n",
    "    scores_df,\n",
    "    on=['Month', 'Year'],\n",
    "    how='left'\n",
    ")\n",
    "\n",
    "wide_df\n",
    "# Now we have one row for each month. That row has 10 features (an aggregated and weighted score for each topic) and an outcome variable (the MCSI score for that month)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec035ab3-bd62-45ce-a592-abb6b7cb98a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create lag feature (okay because we are splitting temporally for train/validate sets)\n",
    "wide_df['prev_score'] = wide_df['score'].shift(1)\n",
    "\n",
    "# Manually add back the score from 12/2024 to minimize data loss\n",
    "wide_df.loc[(wide_df['Year'] == 2025) & (wide_df['Month'] == 1), 'prev_score'] = 74\n",
    "\n",
    "wide_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76e3e8e5-3d59-4ebb-9dbc-82ddfad50abf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aggregate to internal and external sentiment\n",
    "internal_columns = ['Durable Goods and Big Purchases', 'Gasoline and Energy Prices', 'Income Expectations',\n",
    "                    'Inflation and Prices','Personal Financial Situation','Unemployment and Job Security']\n",
    "external_columns = ['Business and Economic Conditions', 'Government Policy and Inflation Control',\n",
    "                    'Housing Market (Buying/Selling Homes)','Investments and Stock Market Confidence']\n",
    "wide_df['internal_sentiment'] = wide_df[internal_columns].mean(axis=1)\n",
    "wide_df['external_sentiment'] = wide_df[external_columns].mean(axis=1)\n",
    "\n",
    "wide_df = wide_df.drop(['Durable Goods and Big Purchases', 'Gasoline and Energy Prices', 'Income Expectations',\n",
    "                    'Inflation and Prices','Personal Financial Situation','Unemployment and Job Security',\n",
    "                    'Business and Economic Conditions', 'Government Policy and Inflation Control',\n",
    "                    'Housing Market (Buying/Selling Homes)','Investments and Stock Market Confidence'], axis=1)\n",
    "\n",
    "wide_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "id": "bbd1d28e-5bf3-4b91-aab1-f4d81932ea98",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create training and validation splits to fit models\n",
    "train_df = wide_df[wide_df['Month'] < 9]\n",
    "validate_df = wide_df[(wide_df['Month'] >= 9) & (wide_df['Month'] < 11)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "id": "a31b9a48-81b5-4866-bda7-85afbd4053ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting features and outcomes\n",
    "# --- Prepare data ---\n",
    "# Sort for readability\n",
    "train_df = train_df.sort_values(by=[\"Year\", \"Month\"]).reset_index(drop=True)\n",
    "validate_df = validate_df.sort_values(by=[\"Year\", \"Month\"]).reset_index(drop=True)\n",
    "\n",
    "# Define features and target\n",
    "exclude_cols = [\"Month\", \"Year\", \"score\"]\n",
    "X_train = train_df.drop(columns=exclude_cols)\n",
    "y_train = train_df[\"score\"]\n",
    "\n",
    "X_val = validate_df.drop(columns=exclude_cols)\n",
    "y_val = validate_df[\"score\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "id": "9aa43921-acb6-4ed7-a864-aa7a04c21fc7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Ridge Regression Summary ===\n",
      "Alpha (regularization strength): 1.0\n",
      "R² (train): 0.9197\n",
      "R² (validation): -29.1814\n",
      "RMSE (validation): 4.1203\n",
      "\n",
      "--- Coefficients ---\n",
      "Business and Economic Conditions : -0.0660\n",
      "Durable Goods and Big Purchases :  0.6582\n",
      "Gasoline and Energy Prices : -0.2705\n",
      "Government Policy and Inflation Control : -0.9989\n",
      "Housing Market (Buying/Selling Homes) : -0.0777\n",
      "Income Expectations  :  1.2620\n",
      "Inflation and Prices :  2.1281\n",
      "Investments and Stock Market Confidence :  1.8960\n",
      "Personal Financial Situation :  1.4434\n",
      "Unemployment and Job Security : -0.6516\n",
      "prev_score           :  0.5707\n",
      "\n",
      "Intercept: 30.4666\n",
      "\n",
      "=== Train Predictions (first 10) ===\n",
      "   Year  Month  score  predicted_score\n",
      "0  2025      1   71.7        68.727365\n",
      "1  2025      2   64.7        66.551839\n",
      "2  2025      3   57.0        57.695953\n",
      "3  2025      4   52.2        52.252318\n",
      "4  2025      5   52.2        52.448997\n",
      "5  2025      6   60.7        58.881699\n",
      "6  2025      7   61.7        60.976070\n",
      "7  2025      8   58.2        60.865759\n",
      "\n",
      "=== Validation Predictions (first 10) ===\n",
      "   Year  Month  score  predicted_score\n",
      "0  2025      9   55.1        59.749421\n",
      "1  2025     10   53.6        57.112394\n"
     ]
    }
   ],
   "source": [
    "# Ridge Model\n",
    "from sklearn.linear_model import Ridge, Lasso\n",
    "from sklearn.metrics import r2_score, mean_squared_error\n",
    "\n",
    "# --- Train Ridge model ---\n",
    "ridge = Ridge(alpha=1.0)\n",
    "ridge.fit(X_train, y_train)\n",
    "\n",
    "# --- Predictions ---\n",
    "train_df[\"predicted_score\"] = ridge.predict(X_train)\n",
    "validate_df[\"predicted_score\"] = ridge.predict(X_val)\n",
    "\n",
    "# --- Summary ---\n",
    "print(\"=== Ridge Regression Summary ===\")\n",
    "print(f\"Alpha (regularization strength): {ridge.alpha}\")\n",
    "print(f\"R² (train): {ridge.score(X_train, y_train):.4f}\")\n",
    "print(f\"R² (validation): {r2_score(y_val, validate_df['predicted_score']):.4f}\")\n",
    "import numpy as np\n",
    "rmse_val = np.sqrt(mean_squared_error(y_val, validate_df['predicted_score']))\n",
    "print(f\"RMSE (validation): {rmse_val:.4f}\")\n",
    "print(\"\\n--- Coefficients ---\")\n",
    "for name, coef in zip(X_train.columns, ridge.coef_):\n",
    "    print(f\"{name:20s} : {coef: .4f}\")\n",
    "print(f\"\\nIntercept: {ridge.intercept_:.4f}\\n\")\n",
    "\n",
    "# --- Output Tables ---\n",
    "print(\"=== Train Predictions (first 10) ===\")\n",
    "print(train_df[[\"Year\", \"Month\", \"score\", \"predicted_score\"]].head(10))\n",
    "\n",
    "print(\"\\n=== Validation Predictions (first 10) ===\")\n",
    "print(validate_df[[\"Year\", \"Month\", \"score\", \"predicted_score\"]].head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "id": "43d4a544-14b6-409a-93f9-4e2a0cb042e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Lasso Regression Summary ===\n",
      "Alpha (regularization strength): 1.0\n",
      "R² (train): 0.8022\n",
      "R² (validation): -31.9981\n",
      "RMSE (validation): 4.3083\n",
      "\n",
      "--- Coefficients ---\n",
      "Business and Economic Conditions : -0.0660\n",
      "Durable Goods and Big Purchases :  0.6582\n",
      "Gasoline and Energy Prices : -0.2705\n",
      "Government Policy and Inflation Control : -0.9989\n",
      "Housing Market (Buying/Selling Homes) : -0.0777\n",
      "Income Expectations  :  1.2620\n",
      "Inflation and Prices :  2.1281\n",
      "Investments and Stock Market Confidence :  1.8960\n",
      "Personal Financial Situation :  1.4434\n",
      "Unemployment and Job Security : -0.6516\n",
      "prev_score           :  0.5707\n",
      "\n",
      "Intercept: 31.2269\n",
      "\n",
      "=== Train Predictions (first 10) ===\n",
      "   Year  Month  score  predicted_score\n",
      "0  2025      1   71.7        67.388903\n",
      "1  2025      2   64.7        66.280989\n",
      "2  2025      3   57.0        58.663026\n",
      "3  2025      4   52.2        53.640667\n",
      "4  2025      5   52.2        53.401121\n",
      "5  2025      6   60.7        56.293894\n",
      "6  2025      7   61.7        61.148705\n",
      "7  2025      8   58.2        61.582695\n",
      "\n",
      "=== Validation Predictions (first 10) ===\n",
      "   Year  Month  score  predicted_score\n",
      "0  2025      9   55.1        59.753483\n",
      "1  2025     10   53.6        57.532928\n"
     ]
    }
   ],
   "source": [
    "# --- Train Lasso model ---\n",
    "lasso = Lasso(alpha=1.0)\n",
    "lasso.fit(X_train, y_train)\n",
    "\n",
    "# --- Predictions ---\n",
    "train_df[\"predicted_score\"] = lasso.predict(X_train)\n",
    "validate_df[\"predicted_score\"] = lasso.predict(X_val)\n",
    "\n",
    "# --- Summary ---\n",
    "print(\"=== Lasso Regression Summary ===\")\n",
    "print(f\"Alpha (regularization strength): {lasso.alpha}\")\n",
    "print(f\"R² (train): {lasso.score(X_train, y_train):.4f}\")\n",
    "print(f\"R² (validation): {r2_score(y_val, validate_df['predicted_score']):.4f}\")\n",
    "\n",
    "rmse_val = np.sqrt(mean_squared_error(y_val, validate_df['predicted_score']))\n",
    "print(f\"RMSE (validation): {rmse_val:.4f}\")\n",
    "print(\"\\n--- Coefficients ---\")\n",
    "for name, coef in zip(X_train.columns, ridge.coef_):\n",
    "    print(f\"{name:20s} : {coef: .4f}\")\n",
    "print(f\"\\nIntercept: {lasso.intercept_:.4f}\\n\")\n",
    "\n",
    "# --- Output Tables ---\n",
    "print(\"=== Train Predictions (first 10) ===\")\n",
    "print(train_df[[\"Year\", \"Month\", \"score\", \"predicted_score\"]].head(10))\n",
    "\n",
    "print(\"\\n=== Validation Predictions (first 10) ===\")\n",
    "print(validate_df[[\"Year\", \"Month\", \"score\", \"predicted_score\"]].head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8b4b443-a6b5-4687-95f4-30dca6bed7dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "## After I have more data, try without the lag component, then with it\n",
    "\n",
    "## Once we get more data, we might be able to expand to a variety of other models\n",
    "\n",
    "## Then we pick a model and save the trained model to github and deploy it using a streamlit app. We can put all of the preprocessing \n",
    "## stuff into a function so that new data is cleaned as is appropriate and turned into a score. Explain exactly what data is going in with \n",
    "## The API stuff I did."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
